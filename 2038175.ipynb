{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 常规赛：用户购买预测5月第9名\n",
    "注：本项目参考于PGL系列：用户购买预测Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from tqdm import tqdm\r\n",
    "import datetime\r\n",
    "import time\r\n",
    "raw = pd.read_csv('data/data19383/train.csv')\r\n",
    "\r\n",
    "# 将goods_id节点重新编号\r\n",
    "raw['goods_id'] = pd.factorize(raw['goods_id'])[0]\r\n",
    "# 将raw根据customer_id排序并将重新编号\r\n",
    "submission_list = pd.DataFrame(raw.groupby('customer_id')['customer_gender'].last()).fillna(0)\r\n",
    "\r\n",
    "raw = raw.sort_values(['customer_id'])\r\n",
    "raw['customer_id'] = pd.factorize(raw['customer_id'])[0]\r\n",
    "\r\n",
    "# 8月之前的数据作为训练集\r\n",
    "train_raw = raw[raw['order_pay_time'] < '2013-07-31 23:59:59']\r\n",
    "\r\n",
    "# 根据customer_id进行提取\r\n",
    "train_data = pd.DataFrame(train_raw.groupby('customer_id')['customer_gender'].last().fillna(0))\r\n",
    "# 在数据集每出现一次作为一个订单，统计每一个用户出现的次数，作为购买的频次\r\n",
    "train_data['order_detail_count'] = train_raw.groupby('customer_id')['customer_id'].count()\r\n",
    "\r\n",
    "# 8月份的数据作为label_raw\r\n",
    "label_raw = set(raw[raw['order_pay_time'] > '2013-07-31 23:59:59']['customer_id'].dropna())\r\n",
    "# 如果该用户在8月份完成了购买 label=1, 否则为0\r\n",
    "train_data['labels'] = train_data.index.map(lambda x: int(x in label_raw))\r\n",
    "\r\n",
    "# 最后test阶段要对所有的节点做预测，使用全部的raw作为测试数据\r\n",
    "test_data = pd.DataFrame(raw.groupby('customer_id')['customer_gender'].last().fillna(0))\r\n",
    "test_data['order_detail_count'] = raw.groupby('customer_id')['customer_id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "我们对之前的猜想1进行简单验证。对订单数进行排序，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f26ecd176d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将train_data按照订单数从小到大排序\r\n",
    "td = train_data.sort_values(['order_detail_count']).reset_index()\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "plt.figure(figsize=(10,4))\r\n",
    "plt.xlim(0, 1600000)\r\n",
    "plt.plot(td['order_detail_count'], 'r.')\r\n",
    "plt.show()\r\n",
    "# 取td中下个月购买的数据，其index即在订单数中的排序\r\n",
    "idx = td[td['labels'] == 1].index\r\n",
    "# print(idx)\r\n",
    "import seaborn as sns\r\n",
    "sns.boxplot(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1585986\n"
     ]
    }
   ],
   "source": [
    "# 用户的节点数量\r\n",
    "customer_id = test_data.index\r\n",
    "print(len(customer_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 提取所要用到的raw数据\r\n",
    "customer_id = test_data.index\r\n",
    "customer_raw = test_data['order_detail_count']\r\n",
    "\r\n",
    "edge_raw = raw[['customer_id', 'goods_id']]\r\n",
    "\r\n",
    "goods_id = np.sort(edge_raw['goods_id'].unique())\r\n",
    "goods_raw = raw.groupby('goods_id')['goods_id'].count()\r\n",
    "\r\n",
    "# 所有节点数，即用户和商品的总和\r\n",
    "num_custome = len(customer_id)\r\n",
    "num_goods = len(goods_id)\r\n",
    "num_nodes = num_goods + num_custome\r\n",
    "\r\n",
    "# 为每一个节点赋予类别\r\n",
    "node_types = []\r\n",
    "for id_ in goods_id:\r\n",
    "    node_types.append((id_, 'goods'))\r\n",
    "\r\n",
    "for id_ in customer_id:\r\n",
    "    node_types.append((id_+num_goods, 'customer'))\r\n",
    "def log_norm(arr):\r\n",
    "    arr = np.log10(arr + 0.1)\r\n",
    "    return arr / arr.max()\r\n",
    "# 所有节点特征，用户特征使用购买次数作为特征，商品特征为1\r\n",
    "node_features = {'feature':np.concatenate([np.ones_like(goods_raw.values), customer_raw.values]).reshape(-1,1).astype(\"float32\")}\r\n",
    "# 所有的边列表\r\n",
    "edge_list = edge_raw.drop_duplicates(subset=None, keep='first', inplace=False).sort_values(['goods_id'])\r\n",
    "edge_list['customer_id'] += num_goods\r\n",
    "edge_list2 = edge_list[['goods_id', 'customer_id']]\r\n",
    "edge_list = edge_list.values\r\n",
    "edge_list2 = edge_list2.values\r\n",
    "# 添加自环\r\n",
    "edge_list3 = np.repeat(np.expand_dims(goods_id, axis=1), repeats=2, axis=1)\r\n",
    "edge_list4 = np.repeat(np.expand_dims(customer_id, axis=1), repeats=2, axis=1)\r\n",
    "# 无向图，所以将正向和反向列表拼接\r\n",
    "edge_list = np.concatenate([edge_list, edge_list2, edge_list3, edge_list4], axis=0)\r\n",
    "# 定义边列表，类别名称是'buy'\r\n",
    "edge_list = {'buy': edge_list.tolist()}\r\n",
    "\r\n",
    "# 测试节点index，即所有的用户节点id\r\n",
    "# 前0到num_goods-1个节点表示商品，从num_goods到num_nodes表示用户\r\n",
    "test_index = np.concatenate([np.arange(num_goods, num_nodes)]).reshape(-1,1).astype(\"int\")\r\n",
    "\r\n",
    "# 训练节点label\r\n",
    "train_label = train_data['labels'].values\r\n",
    "# 训练节点index，即在trin_raw中的customer_id，数值上从num_goods到num_nodes中取样\r\n",
    "customer_id_train = train_data.index + num_goods\r\n",
    "train_index = np.concatenate([customer_id_train]).reshape(-1,1).astype(\"int\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install pgl -i https://mirror.baidu.com/pypi/simple\r\n",
    "\r\n",
    "import paddle.fluid as fluid\r\n",
    "import paddle.fluid.layers as fl\r\n",
    "import pgl\r\n",
    "from pgl import heter_graph\r\n",
    "from pgl import heter_graph_wrapper\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 异构图GCN模型\n",
    "\n",
    "对每一种边分别全连接，实际上这里只用了一种边('buy')。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def HeteroGCNLayer(gw, edge_types, features, hidden_size=10, norm=None, name=''):\r\n",
    "    def send_func(src_feat, dst_feat, edge_feat):\r\n",
    "        if norm is not None:\r\n",
    "            return src_feat['h'] * src_feat['norm']\r\n",
    "        else:\r\n",
    "            return src_feat['h'] \r\n",
    "    def recv_func(feat):\r\n",
    "        return fluid.layers.sequence_pool(feat, pool_type='sum')\r\n",
    "\r\n",
    "    assert len(edge_types) == len(features)\r\n",
    "    output = []\r\n",
    "    for i in range(len(edge_types)):\r\n",
    "        msg = gw[edge_types[i]].send(send_func, nfeat_list=[('h', features[i]), ('norm', norm[i])])\r\n",
    "        out = gw[edge_types[i]].recv(msg, recv_func)\r\n",
    "        out = fluid.layers.fc(out, size=hidden_size, act='relu')\r\n",
    "        if norm is not None:\r\n",
    "            out = out * norm[i]\r\n",
    "        output.append(out)\r\n",
    "    # list of matrix\r\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 生产图数据\r\n",
    "g = heter_graph.HeterGraph(num_nodes=num_nodes,\r\n",
    "                            edges=edge_list,\r\n",
    "                            node_types=node_types,\r\n",
    "                            node_feat=node_features,)\r\n",
    "                            # edge_feat=edges_weight)\r\n",
    "# 根据节点的度提取归一化特征\r\n",
    "indegree = g.indegree()\r\n",
    "norm = np.zeros_like(indegree, dtype=\"float32\")\r\n",
    "norm[indegree > 0] = np.power(indegree[indegree > 0], -0.5)\r\n",
    "g.node_feat[\"norm\"] = np.expand_dims(norm, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "place = fluid.CUDAPlace(0) \r\n",
    "train_program = fluid.Program()\r\n",
    "startup_program = fluid.Program()\r\n",
    "hidden_size = 16\r\n",
    "# 网络结构\r\n",
    "with fluid.program_guard(train_program, startup_program):\r\n",
    "# create a GraphWrapper as a container for graph data\r\n",
    "    gw = heter_graph_wrapper.HeterGraphWrapper(name='heter_graph',\r\n",
    "                                        place = place,\r\n",
    "                                        edge_types = g.edge_types_info(),\r\n",
    "                                        node_feat=g.node_feat_info(),\r\n",
    "                                        edge_feat=g.edge_feat_info())\r\n",
    "\r\n",
    "    edge_types = ['buy']\r\n",
    "    features = []\r\n",
    "    norms = []\r\n",
    "    for edge_type in edge_types:\r\n",
    "        features.append(gw[edge_type].node_feat['feature'])\r\n",
    "        norms.append(gw[edge_type].node_feat[\"norm\"])\r\n",
    "    output = HeteroGCNLayer(gw, edge_types, features, hidden_size, norms)\r\n",
    "    output1 = []\r\n",
    "    for i in range(len(output)):\r\n",
    "        output1.append(fluid.layers.dropout(\r\n",
    "            output[i], 0.5, dropout_implementation='upscale_in_train'))\r\n",
    "    output = output1\r\n",
    "    # output = HeteroGCNLayer(gw, edge_types, output, hidden_size)\r\n",
    "\r\n",
    "    node_index = fluid.layers.data(\"node_index\", shape=[None, 1], dtype=\"int64\", append_batch_size=False)\r\n",
    "    output1 = []\r\n",
    "    for i in range(len(output)):\r\n",
    "        output1.append(fluid.layers.gather(output[i], node_index))\r\n",
    "    output = output1\r\n",
    "    output = fl.concat(input=output, axis=1)\r\n",
    "\r\n",
    "    output = fluid.layers.fc(output, size=4, bias_attr=False, act='relu', name='fc1')\r\n",
    "    logits = fluid.layers.fc(output, size=2, bias_attr=False, act=None, name='fc2')\r\n",
    "    # pred = fluid.layers.softmax(logits, axis=1)\r\n",
    "    node_label = fluid.layers.data(\"node_label\", shape=[None, 1], dtype=\"float32\")\r\n",
    "    label_64 = fluid.layers.cast(node_label, 'int64')\r\n",
    "    # loss = fluid.layers.cross_entropy(input=pred, label=fluid.layers.concat([1-node_label, node_label], axis=1), soft_label=True)\r\n",
    "    # loss = fluid.layers.sigmoid_cross_entropy_with_logits(x=logits, label=node_label,normalize=False)\r\n",
    "    loss, pred = fluid.layers.softmax_with_cross_entropy(logits=logits, label=label_64, soft_label=False, return_softmax=True, axis=1)\r\n",
    "    loss = fluid.layers.mean(loss) \r\n",
    "\r\n",
    "    # def bce_loss(pred, label, epsilon=1e-05): # 标签都是 0或1，但是计算上log(0)不合法，所以一般将label和pred卡到[eps, 1-eps]范围内\r\n",
    "    #     label = fluid.layers.clip(label, epsilon, 1-epsilon)\r\n",
    "    #     pred = fluid.layers.clip(pred, epsilon, 1-epsilon) # 防止出现log(0)\r\n",
    "\r\n",
    "    #     loss = -1 * (label * fluid.layers.log(pred) + (1 - label) * fluid.layers.log(1 - pred))\r\n",
    "    #     loss = fluid.layers.reduce_mean(loss)\r\n",
    "    #     return loss\r\n",
    "    # loss = bce_loss(pred, node_label)\r\n",
    "    # p2 = fluid.layers.concat([1-pred, pred], axis=1)\r\n",
    "    acc = fluid.layers.accuracy(input=pred, label=fluid.layers.cast(node_label, 'int64'), k=1)\r\n",
    "    output = pred[:,1]\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "test_program = train_program.clone(for_test=True)\r\n",
    "with fluid.program_guard(train_program, startup_program): \r\n",
    "    adam = fluid.optimizer.Adam(\r\n",
    "        learning_rate=1e-2,\r\n",
    "        regularization=fluid.regularizer.L2DecayRegularizer(\r\n",
    "            regularization_coeff=0.0005))\r\n",
    "    adam.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label = train_label.reshape(-1,1).astype(\"float32\")\r\n",
    "index = train_index.reshape(-1,1).astype(\"int\")\r\n",
    "\r\n",
    "exe = fluid.Executor(place)\r\n",
    "exe.run(startup_program)\r\n",
    "feed_dict = gw.to_feed(g)\r\n",
    "\r\n",
    "for epoch in range(20):\r\n",
    "    feed_dict['node_index'] = index\r\n",
    "    feed_dict['node_label'] = label\r\n",
    "\r\n",
    "    train_loss, acc_, pred_ = exe.run(train_program, feed=feed_dict, fetch_list=[loss,acc,output,], return_numpy=True)\r\n",
    "    # train_loss, pred_  = exe.run(train_program, feed=feed_dict, fetch_list=[loss, pred ], return_numpy=True)\r\n",
    "    print('Epoch %d | Loss: %f | Acc: %f '%(epoch, train_loss[0], acc_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 在训练的模型基础下，对全部节点输出类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feed_dict['node_index'] = test_index.reshape(-1,1).astype(\"int\")\r\n",
    "feed_dict[\"node_label\"] = np.ones_like(test_index).reshape(-1,1).astype(\"float32\")\r\n",
    "test_pred = exe.run(test_program,\r\n",
    "                    feed=feed_dict,\r\n",
    "                    fetch_list=[pred],\r\n",
    "                    return_numpy=True)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pred[0].min(),test_pred[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(test_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 后处理和输出预测结果submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_ = np.median(test_pred[0]) \r\n",
    "# 区间选择归一化，减少map函数的计算量\r\n",
    "def f(x):\r\n",
    "    if x < max_:\r\n",
    "        return 0\r\n",
    "    elif x >  max_:\r\n",
    "        return 1\r\n",
    "    # else:\r\n",
    "    #     return x / max_ \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_list['result'] = test_pred[0].reshape(-1).tolist()\r\n",
    "submission_list['result'] = submission_list['result'].map(f)\r\n",
    "subm = pd.DataFrame(submission_list['result'])\r\n",
    "subm.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 特征提取参考"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 对数据进行预处理\r\n",
    "def prerpocess(raw, train='train'):\r\n",
    "    st = time.time()\r\n",
    "    # 性别：0未知，1男，2女\r\n",
    "    data = pd.DataFrame(raw.groupby('customer_id')['customer_gender'].last().fillna(0))\r\n",
    "    # 添加商品相关信息\r\n",
    "    data[['goods_id_last', 'goods_status_last', 'goods_price_last', 'goods_has_discount_last', 'goods_list_time_last', 'goods_delist_time_last']] = raw.groupby('customer_id')['goods_id', 'goods_status', 'goods_price', 'goods_has_discount', 'goods_list_time', 'goods_delist_time'].last()\r\n",
    "    # 添加订单相关信息\r\n",
    "    data[['order_total_num_last', 'order_amount_last',\r\n",
    "       'order_total_payment_last', 'order_total_discount_last', 'order_pay_time_last',\r\n",
    "       'order_status_last', 'order_count_last', 'is_customer_rate_last',\r\n",
    "       'order_detail_status_last', 'order_detail_goods_num_last', 'order_detail_amount_last',\r\n",
    "       'order_detail_payment_last', 'order_detail_discount_last']] = raw.groupby('customer_id')['order_total_num', 'order_amount',\r\n",
    "       'order_total_payment', 'order_total_discount', 'order_pay_time',\r\n",
    "       'order_status', 'order_count', 'is_customer_rate',\r\n",
    "       'order_detail_status', 'order_detail_goods_num', 'order_detail_amount',\r\n",
    "       'order_detail_payment', 'order_detail_discount'].last()\r\n",
    "    # 添加商品原始价格统计字段\r\n",
    "    data[['good_price_std', 'good_price_mean', 'good_price_min', 'good_price_max']] = raw.groupby('customer_id')['goods_price'].agg({'good_price_std':'std', 'good_price_mean':'mean', 'good_price_min':'min', 'good_price_max':'max'})\r\n",
    "    # 添加订单实付金额统计字段\r\n",
    "    data[['order_detail_payment_std', 'order_detail_payment_mean', 'order_detail_payment_min', 'order_detail_payment_max']] = raw.groupby('customer_id')['order_detail_payment'].agg({'order_detail_payment_std':'std', 'order_detail_payment_mean':'mean', 'order_detail_payment_min':'min', 'order_detail_payment_max':'max'})\r\n",
    "    # 用户购买的订单数量\r\n",
    "    data['count'] = raw.groupby('customer_id')['order_id'].nunique()\r\n",
    "    # 用户购买的商品数量\r\n",
    "    data['goods_count'] = raw.groupby('customer_id')['order_total_num'].sum()\r\n",
    "    # 用户所在省份\r\n",
    "    data['customer_province'] = raw.groupby('customer_id')['customer_province'].last()\r\n",
    "    # 用户所在城市\r\n",
    "    data['customer_city'] = raw.groupby('customer_id')['customer_city'].last()\r\n",
    "    # 用户是否评价 统计结果（平均，综合）\r\n",
    "    data[['is_customer_rate_ratio','is_customer_rate_sum']] = raw.groupby('customer_id')['is_customer_rate'].agg({'is_customer_rate_ratio':np.mean,'is_customer_rate_sum':np.sum})\r\n",
    "    # 用户购买的goods数量，一个订单商品，即order_detail_id（goods_id）\r\n",
    "    data['order_detail_count'] = raw.groupby('customer_id')['customer_id'].count()\r\n",
    "    # 商品折扣统计属性（sum, ave）\r\n",
    "    data[['goods_has_discount_sum','goods_has_discount_ave']] = raw.groupby('customer_id')['goods_has_discount'].agg({'goods_has_discount_sum':np.sum,'goods_has_discount_ave':np.mean})\r\n",
    "    # 订单实付金额 统计属性（sum, ave）\r\n",
    "    data[['order_total_payment_sum','order_total_ave_pay']] = raw.groupby('customer_id')['order_total_payment'].agg({'order_total_payment_sum':np.sum,'order_total_ave_pay':np.mean})\r\n",
    "    # 订单商品数量 统计属性（sum, ave）\r\n",
    "    data[['order_total_num_sum', 'order_total_num_ave']] = raw.groupby('customer_id')['order_total_num'].agg({'order_total_num_sum':np.sum,'order_total_num_ave':np.mean})\r\n",
    "\r\n",
    "    # 时间转换\r\n",
    "    def time2multi(x):\r\n",
    "        t=datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\r\n",
    "        return pd.Series([t.month,t.day,t.weekday(),t.hour,t.minute,t.second])\r\n",
    "    # 订单付款时间\r\n",
    "    data[['order_pay_time_last_m','order_pay_time_last_d','order_pay_time_last_week','order_pay_time_last_h','order_pay_time_last_min','order_pay_time_last_s']]=data['order_pay_time_last'].apply(time2multi)\r\n",
    "    #data[['order_pay_time_last_m','order_pay_time_last_d','order_pay_time_last_week','order_pay_time_last_h','order_pay_time_last_min','order_pay_time_last_s']] = raw.groupby('customer_id')['order_pay_time_last_m','order_pay_time_last_d','order_pay_time_last_week','order_pay_time_last_h','order_pay_time_last_min','order_pay_time_last_s'].last()\r\n",
    "    # 起始时间是从2013-01-01开始\r\n",
    "    t_str='2013-01-01 00:00:00'\r\n",
    "    t=datetime.datetime.strptime(t_str, '%Y-%m-%d %H:%M:%S')\r\n",
    "    # 商品最新上架时间diff （距离起始时间）\r\n",
    "    data['goods_list_time_diff'] = data['goods_list_time_last'].map(lambda x:(datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')-t).days/364)\r\n",
    "    # 商品最新下架时间diff （距离起始时间）\r\n",
    "    data['goods_delist_time_diff'] = data['goods_delist_time_last'].map(lambda x:(datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')-t).days/364)\r\n",
    "    # 商品展示时间\r\n",
    "    data['goods_diff'] = data['goods_delist_time_diff'] - data['goods_list_time_diff']\r\n",
    "    # 付款时间diff (距离起始时间)\r\n",
    "    data['order_pay_time_last_diff'] = data['order_pay_time_last'].map(lambda x:(datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')-t).days/364)\r\n",
    "    ed = time.time()\r\n",
    "    # 输出preprocess计算时间\r\n",
    "    print(ed-st)\r\n",
    "    \r\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 8月之前的数据作为训练集\r\n",
    "train_raw = raw[raw['order_pay_time'] < '2013-07-31 23:59:59']\r\n",
    "train_raw = prerpocess(train_raw)\r\n",
    "# 8月份的数据作为label_raw\r\n",
    "label_raw = set(raw[raw['order_pay_time'] > '2013-07-31 23:59:59']['customer_id'].dropna())\r\n",
    "# 如果该用户在8月份完成了购买 label=1, 否则为0\r\n",
    "train_raw['labels']=train_raw.index.map(lambda x:int(x in label_raw))\r\n",
    "test = prerpocess(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 这些时间，之前已经根据时间提取了特征 原始的格式没法直接参与训练\r\n",
    "train_data = train_raw.drop(['goods_list_time_last', 'goods_delist_time_last', 'order_pay_time_last'], axis=1)\r\n",
    "# 暂时没有处理customer_province, customer_city 可以先去掉\r\n",
    "train_data = train_data.drop(['customer_province', 'customer_city'], axis=1)\r\n",
    "# 分类变量\r\n",
    "catel = ['order_pay_time_last_h', 'order_pay_time_last_week', 'order_pay_time_last_m', 'order_detail_status_last', 'order_status_last', 'goods_status_last', 'goods_id_last', 'customer_gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.6.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
